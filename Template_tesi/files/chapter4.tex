\chapter{Apprendimento democratizzato: Algoritmo e risultati}\label{ch:chapter4}
Riportiamo di seguito il DemLearn tramite uno pseudocodice.

\begin{algorithm}[H]
 \KwData{K, T, $\tau$}
 \For{t=0,...,T-1}{
 	\For{learning agent n=1,...,N}{
 	L'agente \textsl{n} usa il modello del gruppo superiore $w_{n,t}^{(1)}$ come modello iniziale. L'agente \textsl{n} aggiorna iterativamente il modello di apprendimento personalizzato $w_{(n,t+1)}^{(0)}$ come minimizzatore inesatto,  ovvero basato sul gradiente, del seguente problema: $min_{w\in W}L_n^{(0)}(w|D_n)+\frac{\mu}{2}||w-w_{(n,t)}^{(1)}||^2$ \hspace{1cm} (8) L'agente \textsl{n} invia il modello di apprendimento aggiornato al server.
 	}
 	\If{t mod $\tau$=0} {
 	Il server ricostruisce la struttura gerarchica mediante l'algoritmo di clustering.
 	}
 	Aggiornamento gerarchico: ogni gruppo i ad ogni livello k esegue un aggiornamento per il suo modello di apprendimento dal basso verso l'alto per aggiornare il contributo dei membri del gruppo. $w_{(i,t+1)}^{(k)}=\sum_{j\in S_{(i,k)}}\frac{N_{(g,j)}^{(k-1)}}{N_{(g,i)}^{(k)}}w_{(j,t+1)}^{(k-1)}$\hspace{1cm} (9) Dopo che il modello di livello superiore è stato aggiornato, i livelli inferiori iniziano ad aggiornarsi dall'alto verso il basso per il contributo del gruppo superiore come segue: $w_{(i,t+1)}^{(k)}=\alpha w_{(t+1)}^{(k+1)}+(1-\alpha )w_{(i,t+1)}^{(k)}$ \hspace{1cm} (10) I modelli di apprendimento aggiornati al livello 1 (vale a dire, $w_{(t+1)}^{(1)}$) vengono quindi trasmessi a tutti gli agenti per aggiornare i loro modelli locali seguendo l'equazione (10).}
\caption{Algoritmo democratizzato}
\end{algorithm}
In questo paragrafo, convalidiamo l'efficacia dell'algoritmo DemLearn con MNIST, Fashion-MNIST [21], Set di dati Federated Extended MNIST e CIFAR-10 rispettivamente per il riconoscimento di cifre scritte a mano, immagini di moda e per il riconoscimento di oggetti. Conduciamo gli esperimenti con 50 clienti, in cui ogni cliente ha numeri mediani di campioni di dati a 64, 70 e 785 con MNIST, set di dati Fashion MNIST e CIFAR-10, rispettivamente. Diversamente da questi tre set di dati, sperimentiamo anche il set di dati FE-MNIST che ha un numero maggiore di classi come 10 cifre, 25 minuscole e 25 maiuscole. Di conseguenza, selezioniamo 50 clienti da 3559 utenti che hanno almeno 50 campioni di dati nel set di dati FE-MNIST. Utilizzando questi set di dati, il 20\% dei campioni di dati su ciascun client viene utilizzato per valutare le prestazioni di test del modello. Dividiamo il set di dati totale in modo tale che ogni cliente disponga di una piccola quantità di dati da due etichette specifiche tra i dieci complessivi in entrambi i set di dati. In tal modo, replichiamo uno scenario di set di dati personali distorti, ovvero dati altamente sbilanciati e un numero limitato di campioni di addestramento possono essere raccolti presso gli agenti. I modelli di apprendimento sono costituiti da due livelli di convoluzione seguiti da due livelli di pooling e due livelli completamente connessi, mentre nel set di dati CIFAR-10 vengono utilizzati tre livelli di convoluzione. Impostiamo il periodo di aggiornamento $\tau=1$ e convalidiamo le prestazioni della proposta algoritmo con K = 4 livelli generalizzati. DemLearn, FedAvg e FedProx utilizzano il tasso di apprendimento comune $\eta$ = 0.05, epoca locale E = 2, dimensione batch B = 10.
Per FedProx, impostiamo il parametro $\tau$ = 0,5. Nel frattempo, pFedMe necessita di una messa a punto dettagliata per ottenere un'accuratezza competitiva per diversi set di dati.\\
Gli approcci FL esistenti come FedProx e FedAvg si concentrano maggiormente sulle prestazioni di apprendimento del modello globale piuttosto che sulle prestazioni di apprendimento dei clienti. Pertanto, per le prossime applicazioni personalizzate, implementiamo DemLearn e misuriamo le prestazioni di apprendimento di tutti i clienti e dei modelli di gruppo. In particolare, conduciamo valutazioni per la specializzazione (C-SPE) e la generalizzazione (C-GEN) dei modelli di apprendimento in media presso gli agenti che sono definiti solo come le prestazioni nei loro dati di test locali e i dati di test collettivi di tutti gli agenti nella regione. Di conseguenza, indichiamo Global come prestazione del modello globale; e GGEN e G-SPE sono rispettivamente le prestazioni medie di generalizzazione e specializzazione dei modelli di gruppo. Oltre alle prestazioni C-SPE standard per i modelli locali, le prestazioni C-GEN introdotte sono una metrica importante che mostra le capacità generalizzate dei modelli locali. Anche se i modelli locali distorti possono raggiungere valori C-SPE elevati fin dall'inizio, in particolare a causa dei loro piccoli set di dati locali, hanno ancora capacità generalizzate molto basse che possono aiutare a produrre buone previsioni in base ai frequenti cambiamenti degli utenti. Nel frattempo, i modelli globali e di gruppo hanno le capacità generalizzate più elevate, ma capacità specializzate inferiori durante la distribuzione ai client.\\\\
Nelle figure seguenti sono stati condotti alcuni confronti delle prestazioni con i seguenti metodi, DemLearn con i tre metodi FL, FedAvg, FedProx e pFedMe come linee di base su quattro set di dati di riferimento, MNIST, Fashion MNIST, FE- MNIST e CIFAR-10. Le valutazioni sperimentali mostrano che l'approccio proposto supera le linee di base in termini di velocità di convergenza, in particolare per ottenere migliori prestazioni di generalizzazione del client. Osserviamo che il modello locale richiede solo 40 round per raggiungere il livello di prestazioni C-GEN dell'80\% utilizzando l'algoritmo proposto, mentre gli algoritmi FL esistenti come FedProx, FedAvg e pFedMe impiegano più di 80 round globali per raggiungere un livello quasi competitivo livello di prestazioni come il nostro. Inoltre, dopo 100 round, Dem Learn ottiene prestazioni di generalizzazione del cliente medie migliori (ad esempio, 88,77\%) tra i modelli di client e prestazioni C-SPE  comparabili a partire da FedAvg e pFedMe.\\
\includegraphics[scale=0.4]{DemLearnMNIST}\\
Notiamo che DemLearn ha prestazioni nettamente superiori con il set di dati MNIST\\\\
\includegraphics[scale=0.4]{DemLearnFashionMNIST}\\
Anche qui DemLearn è più veloce dei suoi concorrenti con il set dati FashionMNIST\\\\
\includegraphics[scale=0.4]{DemLearnFederatedExtMNIST}\\\\
Tutti gli altri algoritmi hanno mostrato prestazioni inferiori e più fluttuanti rispetto a quelle degli altri algoritmi per il set di dati FE-MNIST. pFedMe ottiene un lento miglioramento dei modelli client sia nella specializzazione che nella generalizzazione. Nel frattempo, DemLearn mostra velocità ed efficienza di convergenza stabili per ottenere prestazioni costantemente elevate dei modelli di apprendimento a tutti i livelli.\\\\
\includegraphics[scale=0.5]{cifar10Comparison}\\\\
Osserviamo che DemLearn subisce un leggero degrado delle prestazioni C-SPE e Global per ottenere prestazioni C-GEN elevate. Dopo 100 round, DemLearn dimostra buone capacità di apprendimento di compromesso dei modelli client con C-SPE elevato (79,09\%) prestazioni C-GEN (57\%) e mentre altri algoritmi di base producono solo modelli locali distorti con capacità generalizzate basse.\\\\
\includegraphics[scale=0.5]{AlgoStructureComp}

